{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPUnt7MLyXMN"
      },
      "source": [
        "## Sesión 2.3.2 Clasificación de texto con scikit-learn y TFIDF\n",
        "\n",
        "En esta sesión vamos a ver cómo podemos desarrollar un clasificador de texto sencillo con la librería scikit y la representación de texto de la bolsa de palabras usando TFIDF y BM25.\n",
        "\n",
        "Vamos a usar el dataset de la sesión 2.1 que tiene etiquetado los tuits como positivos y negativos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2_-eP2xhwcu"
      },
      "outputs": [],
      "source": [
        "# Instalamos las librerías necesarias y descargamos los recursos\n",
        "!pip3 install -U scikit-learn\n",
        "# Descargamos un fichero python con la implementación del BM25\n",
        "!wget --no-check-certificate https://valencia.inf.um.es/dlpln/BM25.py\n",
        "\n",
        "# Descargamos el fichero datasetEspañol.csv\n",
        "!wget --no-check-certificate https://valencia.inf.um.es/dlpln/datasetEspañol.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7fTg51ByRvw"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "df = pandas.read_csv(\"datasetEspañol.csv\",encoding=\"UTF-8\")\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjpzzCCM7_fn"
      },
      "source": [
        "## Apartado 1 División de conjunto de entrenamiento y test (Resuelto)\n",
        "\n",
        "Dividimos entre conjunto de entrenamiento, test y validación de manera aleatoria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMszAwYr8L8l"
      },
      "outputs": [],
      "source": [
        "p_train = 0.80 # Porcentaje de train.\n",
        "p_test = 0.20 # Porcentaje de train.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size = p_test)\n",
        "\n",
        "# Ponemos en lower_case los dos conjuntos de tweets\n",
        "# Aquí se podría hacer un preprocesamiento como vimos en la sesión práctica 1\n",
        "df_train.tweet = df_train.tweet.apply(lambda x: x.lower())\n",
        "df_test.tweet = df_test.tweet.apply(lambda x: x.lower())\n",
        "\n",
        "print(\"Ejemplos usados para entrenar: \", len(df_train))\n",
        "print(\"Ejemplos usados para test: \", len(df_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHCGEzfE8RY2"
      },
      "source": [
        "## Apartado 2 Generación de los modelos de BoW (Resuelto)\n",
        "Generamos los modelos de bolsa de palabras usando el CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "463DI0Xy5JqG"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "# Pueden haber distintas opciones para crear el CountVectorizer() como eliminar las stopwords, usar ngramas, etc.\n",
        "X_train_counts = count_vect.fit_transform(df_train.tweet)\n",
        "X_train_counts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kliGsSe55WvV"
      },
      "outputs": [],
      "source": [
        "# Consultamos cuál sería el índice de un término\n",
        "count_vect.vocabulary_.get(u'coronavirus')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQvnYpMS5xkX"
      },
      "source": [
        "### Modelo de TF, TFIDF y BM25\n",
        "Vamos a probar cómo funcionan los distintos modelos tanto de TF, TFIDF y BM25. Para ello generaremos 3 modelos distintos para entrenamiento y validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emd8J4jF5zIt"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Generamos primeramente el TF usando el parámetro \"use_idf=false\"\n",
        "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
        "X_train_tf = tf_transformer.transform(X_train_counts)\n",
        "X_train_tf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iaZXruJ6RYF"
      },
      "outputs": [],
      "source": [
        "# Calculamos el TFIDF ahora y lo guardamos en X_train_tfidf\n",
        "tfidf_transformer = TfidfTransformer().fit(X_train_counts)\n",
        "X_train_tfidf = tfidf_transformer.transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmigCFdXhr9F"
      },
      "outputs": [],
      "source": [
        "from BM25 import BM25Transformer\n",
        "# Calculamos el BM25 ahora y lo guardamos en X_train_bm25\n",
        "bm25_transformer = BM25fTransformer().fit(X_train_counts)\n",
        "X_train_bm25 = bm25_transformer.transform(X_train_counts)\n",
        "X_train_bm25.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43lCUHLd6cpI"
      },
      "source": [
        "### Entrenamos un mismo algoritmo de clasificación con los modelos\n",
        "Entrenamos un algoritmo de clasificación el LinearSVM con TF, TFIDF y BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8JFlarP6fdU"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Entrenamos el modelo para TF y lo guardamos en clf_tf\n",
        "clf_tf = LinearSVC(random_state=0, tol=1e-5, dual=True).fit(X_train_tf, df_train.label)\n",
        "\n",
        "# Entrenamos el modelo para TFIDF y lo guardamos en clf_tfidf\n",
        "clf_tfidf = LinearSVC(random_state=0, tol=1e-5, dual=True).fit(X_train_tfidf, df_train.label)\n",
        "\n",
        "# Entrenamos el modelo para TF y lo guardamos en clf_bm25\n",
        "clf_bm25 = LinearSVC(random_state=0, tol=1e-5, dual=True).fit(X_train_bm25, df_train.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHmxSMp36uQx"
      },
      "source": [
        "Probamos ejemplos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNFkXsOC6vmg"
      },
      "outputs": [],
      "source": [
        "docs_new = ['no me fío del gobierno', 'aumentan los fallecidos','desciende la incidencia del virus']\n",
        "X_new_counts = count_vect.transform(docs_new)\n",
        "# Obtenemos los vectores para TF y los guardamos en X_new_tf\n",
        "X_new_tf = tf_transformer.transform(X_new_counts)\n",
        "\n",
        "# Obtenermos los vectores para TFIDF y los guardamos en X_new_tfidf\n",
        "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
        "\n",
        "# Obtenemos los vectores para BM25 y los guardamos en X_new_bm25\n",
        "X_new_bm25 = bm25_transformer.transform(X_new_counts)\n",
        "\n",
        "# Predecimos entonces las categorías para TF y las guardamos en predicted_tf\n",
        "predicted_tf = clf_tf.predict(X_new_tf)\n",
        "\n",
        "# Predecimos entonces las categorías para TFIDF y las guardamos en predicted_tfidf\n",
        "predicted_tfidf = clf_tfidf.predict(X_new_tfidf)\n",
        "\n",
        "# Predecimos entonces las categorías para BM25 y las guardamos en predicted_bm25\n",
        "predicted_bm25 = clf_bm25.predict(X_new_bm25)\n",
        "\n",
        "# Imprimimos los textos y su predicción para TF\n",
        "for doc, category_tf in zip(docs_new, predicted_tf):\n",
        "  print('TF: %r => %s' % (doc, category_tf))\n",
        "\n",
        "# Imprimimos los textos y su predicción para TFIDF\n",
        "for doc, category_tfidf in zip(docs_new, predicted_tfidf):\n",
        "  print('TFIDF: %r => %s' % (doc, category_tfidf))\n",
        "\n",
        "# Imprimimos los textos y su predicción para BM25\n",
        "for doc, category_bm25 in zip(docs_new, predicted_bm25):\n",
        "  print('BM25: %r => %s' % (doc, category_bm25))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdweP0w1-3Rt"
      },
      "source": [
        "## Apartado 3 Creamos los modelos mediante pipeline\n",
        "Para simplificar el código de creación de modelos se puede hacer creando un pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBu9ZzNa-5iN"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "# Se pueden crear modelos mediante Pipeline\n",
        "# Creamos el pipeline de TF con LinearSVC\n",
        "clf_tf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tf', TfidfTransformer(use_idf=False)),\n",
        "    ('clf', LinearSVC(random_state=0, tol=1e-5)),])\n",
        "\n",
        "# Creamos el pipeline de TFIDF con LinearSVC y lo guardamos en clf_tfidf\n",
        "clf_tfidf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LinearSVC(random_state=0, tol=1e-5)),])\n",
        "\n",
        "# Creamos el pipeline de BM25 con LinearSVC y lo guardamos en clf_bm25\n",
        "clf_bm25 = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('bm25', BM25Transformer()),\n",
        "    ('clf', LinearSVC(random_state=0, tol=1e-5)),])\n",
        "\n",
        "# Entrenamos el modelo de TF con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_tf.fit(df_train.tweet, df_train.label)\n",
        "\n",
        "# Entrenamos el modelo de TFIDF con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_tfidf.fit(df_train.tweet, df_train.label)\n",
        "\n",
        "# Entrenamos el modelo de BM25 con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_bm25.fit(df_train.tweet, df_train.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09J1R6Wz-Owz"
      },
      "source": [
        "Evaluamos el accuracy del test en los 3 algoritmos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOPVJ7E--XdJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Evaluamos el TF\n",
        "predicted_tf = clf_tf.predict(df_test.tweet)\n",
        "accuracy_tf = np.mean(predicted_tf == df_test.label)\n",
        "\n",
        "print(\"Resultados TF ----- Accuracy:\", accuracy_tf)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(df_test.label, predicted_tf))\n",
        "\n",
        "# Evaluamos el TFIDF\n",
        "predicted_tfidf = clf_tfidf.predict(df_test.tweet)\n",
        "accuracy_tfidf = np.mean(predicted_tfidf == df_test.label)\n",
        "\n",
        "print(\"Resultados TFIDF ----- Accuracy:\", accuracy_tfidf)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(df_test.label, predicted_tfidf))\n",
        "\n",
        "# Evaluamos el BM25\n",
        "predicted_bm25 = clf_bm25.predict(df_test.tweet)\n",
        "accuracy_bm25 = np.mean(predicted_bm25 == df_test.label)\n",
        "\n",
        "print(\"Resultados BM25 ----- Accuracy:\", accuracy_bm25)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(df_test.label, predicted_bm25))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONFDm9Qz_kuK"
      },
      "source": [
        "## Apartado 4 Imprimimos las matrices de confusión\n",
        "Para que se vean más bonitas podemos instalar las librerías matplotlib y seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axwomi4Bhr9G"
      },
      "outputs": [],
      "source": [
        "!pip3 install -U matplotlib\n",
        "!pip3 install -U seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3GG1KkHBX0H"
      },
      "outputs": [],
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pintamos la matriz de confusión de TF\n",
        "array_tf = metrics.confusion_matrix(df_test.label, predicted_tf)\n",
        "df_cm_tf = pd.DataFrame(array_tf)\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm_tf, annot=True, fmt=\"d\")\n",
        "\n",
        "# Pintamos la matriz de confusión de TFIDF\n",
        "array_tfidf = metrics.confusion_matrix(df_test.label, predicted_tfidf)\n",
        "df_cm_tfidf = pd.DataFrame(array_tfidf)\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm_tfidf, annot=True, fmt=\"d\")\n",
        "\n",
        "# Pintamos la matriz de confusión de BM25\n",
        "array_bm25 = metrics.confusion_matrix(df_test.label, predicted_bm25)\n",
        "df_cm_bm25 = pd.DataFrame(array_bm25)\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm_bm25, annot=True, fmt=\"d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXzhkX65K2Qb"
      },
      "source": [
        "## Apartado 5 - Guardamos y cargamos el modelo (Resuelto)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKIIVKRaK5K3"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Podemos gardar el modelo a algún archivo\n",
        "modTF_file = \"TF_model.pkl\"\n",
        "joblib.dump(clf_tf, modTF_file)\n",
        "\n",
        "# Lo cargamos desde el fichero\n",
        "TF_model = joblib.load(modTF_file)\n",
        "\n",
        "# Volvemos a calcular el accuracy de los datos de test\n",
        "score = TF_model.score(df_test.tweet, df_test.label)\n",
        "print(\"Test accuracy: {0:.8f} %\".format(100 * score))\n",
        "\n",
        "# Otra forma de calcular el accuracy es\n",
        "predicted_tf = TF_model.predict(df_test.tweet)\n",
        "np.mean(predicted_tf == df_test.label)\n",
        "\n",
        "# Probamos de nuevo los ejemplos para la clasificación\n",
        "docs_new = ['no me fío del gobierno', 'aumentan los fallecidos','desciende la incidencia del virus']\n",
        "\n",
        "# Predecimos\n",
        "predicted_tf = TF_model.predict(docs_new)\n",
        "\n",
        "# Imprimimos los textos y su predicción para TF\n",
        "for doc, category_tf in zip(docs_new, predicted_tf):\n",
        "  print('TF: %r => %s' % (doc, category_tf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVv97m9c4TXJ"
      },
      "source": [
        "# Apartado 6 Creamos modelos con otros algoritmos de clasificación de scikit-learn\n",
        "\n",
        "En la documentación de scikit-learn se describen multitud de clasificadores que se pueden utilizar https://scikit-learn.org/stable/supervised_learning.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USWYB8KsGGWC"
      },
      "outputs": [],
      "source": [
        "# Creamos y entrenamos modelos mediante Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Se pueden crear modelos mediante Pipeline\n",
        "# Creamos el pipeline de TF con LinearSVC\n",
        "clf_tf = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(3,5), analyzer=\"char_wb\", min_df=5)),\n",
        "    ('tf', TfidfTransformer(use_idf=False)),\n",
        "    ('clf', RandomForestClassifier(random_state=0)),])\n",
        "\n",
        "# Creamos el pipeline de TFIDF con LinearSVC y lo guardamos en clf_tfidf\n",
        "clf_tfidf = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(3,5), analizer=\"char_wb\", min_df=5)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', RandomForestClassifier(random_state=0)),])\n",
        "\n",
        "# Creamos el pipeline de BM25 con LinearSVC y lo guardamos en clf_bm25\n",
        "clf_bm25 = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(3,5), analizer=\"char_wb\", min_df=5)),\n",
        "    ('bm25', BM25Transformer()),\n",
        "    ('clf', RandomForestClassifier(random_state=0)),])\n",
        "\n",
        "# Entrenamos el modelo de TF con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_tf.fit(df_train.tweet, df_train.label)\n",
        "\n",
        "# Entrenamos el modelo de TFIDF con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_tfidf.fit(df_train.tweet, df_train.label)\n",
        "\n",
        "# Entrenamos el modelo de BM25 con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_bm25.fit(df_train.tweet, df_train.label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOIl6pqcGVRY"
      },
      "outputs": [],
      "source": [
        "# Evaluamos los nuevos modelos\n",
        "import numpy as np\n",
        "\n",
        "# Evaluamos el TF\n",
        "predicted_tf = clf_tf.predict(df_test.tweet)\n",
        "accuracy_tf = np.mean(predicted_tf == df_test.label)\n",
        "\n",
        "print(\"Resultados TF ----- Accuracy:\", accuracy_tf)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(df_test.label, predicted_tf))\n",
        "\n",
        "# Evaluamos el TFIDF\n",
        "predicted_tfidf = clf_tfidf.predict(df_test.tweet)\n",
        "accuracy_tfidf = np.mean(predicted_tfidf == df_test.label)\n",
        "\n",
        "print(\"Resultados TFIDF ----- Accuracy:\", accuracy_tfidf)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(df_test.label, predicted_tfidf))\n",
        "\n",
        "# Evaluamos el BM25\n",
        "predicted_bm25 = clf_bm25.predict(df_test.tweet)\n",
        "accuracy_bm25 = np.mean(predicted_bm25 == df_test.label)\n",
        "\n",
        "print(\"Resultados BM25 ----- Accuracy:\", accuracy_bm25)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(df_test.label, predicted_bm25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoHs2acO43zp"
      },
      "outputs": [],
      "source": [
        "# Creamos y entrenamos modelos mediante Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Se pueden crear modelos mediante Pipeline\n",
        "# Creamos el pipeline de TF con LinearSVC\n",
        "clf_tf = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(3,5), analyzer=\"char_wb\", min_df=5)),\n",
        "    ('tf', TfidfTransformer(use_idf=False)),\n",
        "    ('clf', LinearSVC(random_state=0, tol=1e-5, dual=True)),])\n",
        "\n",
        "# Creamos el pipeline de TFIDF con LinearSVC y lo guardamos en clf_tfidf\n",
        "clf_tfidf = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(3,5), analizer=\"char_wb\", min_df=5)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', LinearSVC(random_state=0, tol=1e-5, dual=True)),])\n",
        "\n",
        "# Creamos el pipeline de BM25 con LinearSVC y lo guardamos en clf_bm25\n",
        "clf_bm25 = Pipeline([\n",
        "    ('vect', CountVectorizer(ngram_range=(3,5), analizer=\"char_wb\", min_df=5)),\n",
        "    ('bm25', BM25Transformer()),\n",
        "    ('clf', LinearSVC(random_state=0, tol=1e-5, dual=True)),])\n",
        "\n",
        "# Entrenamos el modelo de TF con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_tf.fit(df_train.tweet, df_train.label)\n",
        "\n",
        "# Entrenamos el modelo de TFIDF con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_tfidf.fit(df_train.tweet, df_train.label)\n",
        "\n",
        "# Entrenamos el modelo de BM25 con el conjunto de entrenamiento con sus etiquetas\n",
        "clf_bm25.fit(df_train.tweet, df_train.label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daFw0ue75-Cp"
      },
      "outputs": [],
      "source": [
        "# Evaluamos los nuevos modelos\n",
        "import numpy as np\n",
        "\n",
        "# Evaluamos el TF\n",
        "predicted_tf = clf_tf.predict(df_test.tweet)\n",
        "accuracy_tf = np.mean(predicted_tf == df_test.label)\n",
        "\n",
        "print(\"Resultados TF ----- Accuracy:\", accuracy_tf)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(df_test.label, predicted_tf))\n",
        "\n",
        "# Evaluamos el TFIDF\n",
        "predicted_tfidf = clf_tfidf.predict(df_test.tweet)\n",
        "accuracy_tfidf = np.mean(predicted_tfidf == df_test.label)\n",
        "\n",
        "print(\"Resultados TFIDF ----- Accuracy:\", accuracy_tfidf)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(df_test.label, predicted_tfidf))\n",
        "\n",
        "# Evaluamos el BM25\n",
        "predicted_bm25 = clf_bm25.predict(df_test.tweet)\n",
        "accuracy_bm25 = np.mean(predicted_bm25 == df_test.label)\n",
        "\n",
        "print(\"Resultados BM25 ----- Accuracy:\", accuracy_bm25)\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(df_test.label, predicted_bm25))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
