{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7Puw4-ALb6A"
      },
      "source": [
        "# Modelos del lenguaje con n-gramas\n",
        "\n",
        "En este cuaderno vamos a ver un ejemplo de cómo hacer un modelo del lenguaje con n-gramas usando la librería nltk y un corpus sobre recetas de cocina extraído de internet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nz6IPgxYcUy"
      },
      "outputs": [],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54_mWHCYLnwR"
      },
      "source": [
        "Descargamos el corpus de recetas de cocina."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlPffSw8YhKf"
      },
      "outputs": [],
      "source": [
        "!wget --no-check-certificate https://valencia.inf.um.es/dlpln/corpusRecetasv2.tgz\n",
        "!tar -xzf corpusRecetasv2.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLBPmGFILtJQ"
      },
      "source": [
        "Utilizando del Tokenizer de nltk creamos un modelo de bigramas y una función para generar texto a partir del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMSPjHdeYL0l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nltk\n",
        "from nltk.lm import Laplace\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "# Descargar los datos necesarios de NLTK si es la primera vez que se usa\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Ruta de la carpeta que contiene los archivos de texto\n",
        "ruta_corpus = \"corpusRecetasv2\"\n",
        "\n",
        "# Leer cada archivo de texto en la carpeta, dividir en frases y tokenizar cada frase\n",
        "corpus_frases = []\n",
        "for archivo in os.listdir(ruta_corpus):\n",
        "    if archivo.endswith(\".txt\"):  # Asegurarse de leer solo archivos de texto\n",
        "        with open(os.path.join(ruta_corpus, archivo), \"r\", encoding=\"utf-8\") as f:\n",
        "            texto = f.read()\n",
        "            # Dividir el texto en frases\n",
        "            frases = sent_tokenize(texto.lower())\n",
        "            # Tokenizar cada frase en palabras y agregar al corpus\n",
        "            for frase in frases:\n",
        "                tokens = word_tokenize(frase)\n",
        "                corpus_frases.append(tokens)\n",
        "\n",
        "# Definir el tamaño del n-grama (por ejemplo, trigramas)\n",
        "n = 3\n",
        "\n",
        "# Preparar los datos de entrenamiento con padding (inserta automáticamente los tokens <s> y </s>)\n",
        "train_data, vocab = padded_everygram_pipeline(n, corpus_frases)\n",
        "\n",
        "# Crear el modelo de lenguaje con suavizado de Laplace\n",
        "modelo_trigramas = Laplace(n)\n",
        "modelo_trigramas.fit(train_data, vocab)\n",
        "\n",
        "# Función para generar texto a partir del modelo\n",
        "def generar_texto(modelo, num_words, texto_inicial=None):\n",
        "    contenido = texto_inicial or []\n",
        "    for _ in range(num_words):\n",
        "        siguiente_palabra = modelo.generate(text_seed=contenido[-(n-1):])  # usar (n-1) palabras anteriores\n",
        "        contenido.append(siguiente_palabra)\n",
        "        if siguiente_palabra == \"</s>\":  # detener si se genera un marcador de fin de oración\n",
        "            break\n",
        "    return ' '.join(contenido)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgyvDvrjL9Ot"
      },
      "source": [
        "Una vez generado el modelo lo podemos guardar en disco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8v0mvKkMAWv"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Guardar el modelo en disco\n",
        "with open('modelo_trigramas.pkl', 'wb') as archivo:\n",
        "    pickle.dump(modelo_trigramas, archivo)\n",
        "    print(\"Modelo de trigramas guardado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ems9TBf-MBzq"
      },
      "source": [
        "Podemos entonces cargar el modelo del disco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHGSIaQpMBIk"
      },
      "outputs": [],
      "source": [
        "# Cargar el modelo desde disco\n",
        "with open('modelo_trigramas.pkl', 'rb') as archivo:\n",
        "    modelo_trigramas_cargado = pickle.load(archivo)\n",
        "    print(\"Modelo de trigramas cargado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K8de4ASMJm0"
      },
      "source": [
        "En estas celdas hacemos pruebas de posibles frases que se pueden generar usando el modelo de trigramas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxRQq90wY-d0"
      },
      "outputs": [],
      "source": [
        "# Generar una frase de ejemplo\n",
        "print(\"Frase generada:\", generar_texto(modelo_trigramas, 40, texto_inicial=[\"pechuga\", \"de\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKAf0aojMhVx"
      },
      "source": [
        "También podemos calcular la probabilidad de una palabra siguiente según un contexto dado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9KT9U-5fw0_"
      },
      "outputs": [],
      "source": [
        "# Función para calcular la probabilidad de una palabra dada un contexto\n",
        "def calcular_probabilidad(modelo, palabra, contexto):\n",
        "    return modelo.score(palabra, contexto)\n",
        "\n",
        "# Ejemplo: Calcular la probabilidad de \"atún\" y \"queso\" en el contexto \"pasta con\"\n",
        "contexto = [\"pasta\", \"con\"]\n",
        "palabra1 = \"atún\"\n",
        "palabra2 = \"queso\"\n",
        "\n",
        "prob_palabra1 = calcular_probabilidad(modelo_trigramas, palabra1, contexto)\n",
        "prob_palabra2 = calcular_probabilidad(modelo_trigramas, palabra2, contexto)\n",
        "\n",
        "print(f\"Probabilidad de '{palabra1}' dado el contexto '{' '.join(contexto)}': {prob_palabra1}\")\n",
        "print(f\"Probabilidad de '{palabra2}' dado el contexto '{' '.join(contexto)}': {prob_palabra2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Oyg_oWqNTI_"
      },
      "source": [
        "Creamos un modelo de cuatrigramas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CanQMhu9NLAL"
      },
      "outputs": [],
      "source": [
        "# Definir el tamaño del n-grama (por ejemplo, trigramas)\n",
        "n = 4\n",
        "\n",
        "# Preparar los datos de entrenamiento con padding (inserta automáticamente los tokens <s> y </s>)\n",
        "train_data, vocab = padded_everygram_pipeline(n, corpus_frases)\n",
        "\n",
        "# Crear el modelo de lenguaje con suavizado de Laplace\n",
        "modelo_cuatrigramas = Laplace(n)\n",
        "modelo_cuatrigramas.fit(train_data, vocab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI38_TNfNVXp"
      },
      "source": [
        "Probamos con generar texto a partir de tres palabras con este nuevo modelo de cuatrigramas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONKnemCXNjEk"
      },
      "outputs": [],
      "source": [
        "# Generar una frase de ejemplo\n",
        "print(\"Frase generada:\", generar_texto(modelo_cuatrigramas, 40, texto_inicial=[\"calentar\", \"el\", \"agua\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbh3mCWdNiz2"
      },
      "source": [
        "Probamos ahora a generar la probabilidad de la siguiente palabra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxgxh7DsN31M"
      },
      "outputs": [],
      "source": [
        "# Ejemplo: Calcular la probabilidad de \"y\" y \"rojo\" en el contexto \"pasta con atún\"\n",
        "contexto = [\"pasta\", \"con\", \"atún\"]\n",
        "palabra1 = \"y\"\n",
        "palabra2 = \"rojo\"\n",
        "\n",
        "prob_palabra1 = calcular_probabilidad(modelo_cuatrigramas, palabra1, contexto)\n",
        "prob_palabra2 = calcular_probabilidad(modelo_cuatrigramas, palabra2, contexto)\n",
        "\n",
        "print(f\"Probabilidad de '{palabra1}' dado el contexto '{' '.join(contexto)}': {prob_palabra1}\")\n",
        "print(f\"Probabilidad de '{palabra2}' dado el contexto '{' '.join(contexto)}': {prob_palabra2}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
