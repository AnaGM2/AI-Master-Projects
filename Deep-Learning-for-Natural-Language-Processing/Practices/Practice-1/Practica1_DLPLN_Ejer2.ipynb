{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Javier García Serrano, Ana Gil Molina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>Ejercicio 2:  (2 puntos)</strong></div>\n",
    "\n",
    "Haz uso del cluster para producir modelos de traducción de inglés a francés. Construye un modelo de traducción basado en seq2seq sin atención. Construye otro modelo de traducción  basado en seq2seq con atención según el modelo de Bahdanau. Usa para ambos tamaños de 256 nodos y 1 capa oculta y entrena las redes durante 100 épocas. Compara los resultados. En la resolución del ejercicio incluye la especificación del trabajo SLURM, el script en Python completo para su ejecución en el cluster y el análisis de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio actual: C:\\Users\\gilpe\\Desktop\\Máster IA\\Primer cuatrimestre\\Deep Learning para Procesamiento del Lenguaje Natural\\Parte I\\Práctica\\Datos\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Cambiar el directorio\n",
    "os.chdir(\"C:/Users/gilpe/Desktop/Máster IA/Primer cuatrimestre/Deep Learning para Procesamiento del Lenguaje Natural/Parte I/Práctica/Datos\")\n",
    "print(\"Directorio actual:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento y Almacenamiento de los Datos\n",
    "\n",
    "Los datos ya se han procesado, y tienen el formato:\n",
    "\n",
    "English + TAB + French\n",
    "\n",
    "Cada palabra se representará con un vector one-hot. Se necesitará un único índice para cada palabra, y mediante la clase `Lang` podremos llevar la cuenta de todos en cada lenguaje gracias a los diccionarios `word2index` e `index2word`. Además, para conocer la frecuencia de cada palabra y eliminar aquellas de menor frecuencia, usaremos `word2count`. El número de palabras se almacenará en `n_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0       # Asignar índice 0 al token SOS inicial\n",
    "EOS_token = 1       # Asignar índice 1 al token EOS final\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name  # Nombre del idioma\n",
    "        self.word2index = {}  # Palabra -> índice\n",
    "        self.word2count = {}  # Palabra -> cantidad de veces que aparece\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}  # Índice -> palabra\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como todos los ficheros son unicode, simplificaremos las cosas pasando todo a ASCII, minúsculas, y eliminando todos los signos de puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la función `readLangs` separamos ficheros en líneas, y las líneas en pares. Los ficheros contienen sentencias del inglés a otros lenguajes. Como en nuestro caso vamos a traducir del inglés al francés, debemos dejar `reverse = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos un poco las sentencias para hacerlo más simple y rápido, quedándonos con sentencias de 10 palabras a lo sumo y del tipo  \\\"I am\\\", \\\"He is\\\", etc. Debemos modificar el código proporcionado en la práctica para que filtre las frases en inglés con los prefijos definidos en `eng_prefixes`, puesto que en el ejemplo de la práctica estas frases se encontraban en `p[1]`, pero ahora se encuentran en `p[0]`, al invertir el orden de los idiomas en la traducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[0].startswith(eng_prefixes)  # Cambiamos p[1] por p[0]\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, el proceso global para preparar los datos incluye:\n",
    "\n",
    "* Leer el fichero de texto, separar en líneas, separar las líneas en pares\n",
    "\n",
    "* Normalizar el texto, filtrar por longitud y contenido\n",
    "\n",
    "* Hacer listas de palabras a partir de los pares de sentencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 2991\n",
      "fra 4601\n",
      "['i m getting a master s degree in education', 'j obtiens un diplome superieur en education']\n"
     ]
    }
   ],
   "source": [
    "# Preparar los datos de inglés a francés\n",
    "input_lang_eng_fra, output_lang_eng_fra, pairs_eng_fra = prepareData('eng', 'fra', False)\n",
    "print(random.choice(pairs_eng_fra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder sin atención"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder basado en atención"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento\n",
    "\n",
    "Modificamos la función `get_dataloader` para que la función `prepareData` tome el parámetro `reverse=Flase`, necesario para que no se invierta el orden de los idiomas, y generar un traductor de inglés a francés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'fra', False)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definido todo este código, el proceso de entrenamiento consiste en los pasos siguientes\n",
    "\n",
    "* Lanzamos un temporizador\n",
    "\n",
    "* Inicializamos los optimizadores y la función de pérdida\n",
    "\n",
    "* Creamos un conjunto de pares de sentencias para el entrenamiento de la red\n",
    "\n",
    "* Inicializamos el array de pérdida para el ploteado de su evolución\n",
    "\n",
    "Tras esto, invocamos a `train` repetidamente y, cada cierto tiempo, imprimimos el progreso del mismo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotear resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificamos la función `evaluateRandomly` para que tome `input_lang`, `output_lang` y `pairs` como parámetro, para poder usarla con los dos modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, input_lang, output_lang, pairs, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar red sin atención\n",
    "\n",
    "El entrenamiento de los modelos se ha realizado en el cluster, y los modelos resultantes ya entrenados se han almacenado en una carpeta *models*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de la carpeta donde guardar los modelos\n",
    "folder_path = 'models/'\n",
    "\n",
    "# Verificar si la carpeta existe, si no, crearla\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 2991\n",
      "fra 4601\n",
      "3m 37s (- 32m 36s) (10 10%) 1.0694\n",
      "7m 21s (- 29m 26s) (20 20%) 0.2276\n",
      "11m 5s (- 25m 52s) (30 30%) 0.1562\n",
      "14m 48s (- 22m 12s) (40 40%) 0.1432\n",
      "18m 30s (- 18m 30s) (50 50%) 0.1374\n",
      "22m 13s (- 14m 48s) (60 60%) 0.1339\n",
      "25m 55s (- 11m 6s) (70 70%) 0.1310\n",
      "29m 38s (- 7m 24s) (80 80%) 0.1289\n",
      "33m 20s (- 3m 42s) (90 90%) 0.1272\n",
      "400m 17s (- 0m 0s) (100 100%) 0.1258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "hidden_size = 256\n",
    "batch_size = 32\n",
    "n_epochs = 100\n",
    "\n",
    "# Datos\n",
    "input_lang_no_attn, output_lang_no_attn, train_dataloader_no_attn = get_dataloader(batch_size)\n",
    "\n",
    "# Modelos\n",
    "encoder_no_attn = EncoderRNN(input_lang_no_attn.n_words, hidden_size).to(device)\n",
    "decoder_no_attn = DecoderRNN(hidden_size, output_lang_no_attn.n_words).to(device)\n",
    "\n",
    "# Entrenamiento\n",
    "train(train_dataloader_no_attn, encoder_no_attn, decoder_no_attn, n_epochs, print_every=10, plot_every=10)\n",
    "\n",
    "# Guardar los modelos dentro de la carpeta\n",
    "torch.save(encoder_no_attn.state_dict(), os.path.join(folder_path, 'encoder_no_attention.pth'))\n",
    "torch.save(decoder_no_attn.state_dict(), os.path.join(folder_path, 'decoder_no_attention.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar red con atención"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 2991\n",
      "fra 4601\n",
      "4m 24s (- 39m 44s) (10 10%) 0.8567\n",
      "9m 1s (- 36m 4s) (20 20%) 0.1809\n",
      "13m 39s (- 31m 51s) (30 30%) 0.1507\n",
      "18m 22s (- 27m 33s) (40 40%) 0.1421\n",
      "23m 3s (- 23m 3s) (50 50%) 0.1378\n",
      "27m 36s (- 18m 24s) (60 60%) 0.1343\n",
      "32m 26s (- 13m 54s) (70 70%) 0.1326\n",
      "37m 15s (- 9m 18s) (80 80%) 0.1311\n",
      "41m 36s (- 4m 37s) (90 90%) 0.1294\n",
      "46m 9s (- 0m 0s) (100 100%) 0.1288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "hidden_size = 256\n",
    "batch_size = 32\n",
    "n_epochs = 100\n",
    "\n",
    "# Datos\n",
    "input_lang_attn, output_lang_attn, train_dataloader_attn = get_dataloader(batch_size)\n",
    "\n",
    "# Modelos\n",
    "encoder_attn = EncoderRNN(input_lang_attn.n_words, hidden_size).to(device)\n",
    "decoder_attn = AttnDecoderRNN(hidden_size, output_lang_attn.n_words).to(device)\n",
    "\n",
    "# Entrenamiento\n",
    "train(train_dataloader_attn, encoder_attn, decoder_attn, n_epochs, print_every=10, plot_every=10)\n",
    "\n",
    "# Guardar los modelos dentro de la carpeta\n",
    "torch.save(encoder_attn.state_dict(), os.path.join(folder_path, 'encoder_attention.pth'))\n",
    "torch.save(decoder_attn.state_dict(), os.path.join(folder_path, 'decoder_attention.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos\n",
    "\n",
    "Una vez entrenados los modelos en el cluster, estos se han guardado en la carpeta *models*. Los descargamos del cluster para poder cargarlos en local ya entrenados, y así evaluar su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 2991\n",
      "fra 4601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilpe\\AppData\\Local\\Temp\\ipykernel_14596\\2616207136.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder_no_attn.load_state_dict(torch.load(os.path.join(folder_path, 'encoder_no_attention.pth'), map_location=device))\n",
      "C:\\Users\\gilpe\\AppData\\Local\\Temp\\ipykernel_14596\\2616207136.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  decoder_no_attn.load_state_dict(torch.load(os.path.join(folder_path, 'decoder_no_attention.pth'), map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos\n",
    "hidden_size = 256\n",
    "batch_size = 32\n",
    "input_lang_no_attn, output_lang_no_attn, train_dataloader_no_attn = get_dataloader(batch_size)\n",
    "\n",
    "# Cargar los modelos sin atención previamente guardados\n",
    "encoder_no_attn = EncoderRNN(input_lang_no_attn.n_words, hidden_size).to(device)\n",
    "decoder_no_attn = DecoderRNN(hidden_size, output_lang_no_attn.n_words).to(device)\n",
    "\n",
    "encoder_no_attn.load_state_dict(torch.load(os.path.join(folder_path, 'encoder_no_attention.pth'), map_location=device))\n",
    "decoder_no_attn.load_state_dict(torch.load(os.path.join(folder_path, 'decoder_no_attention.pth'), map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 2991\n",
      "fra 4601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilpe\\AppData\\Local\\Temp\\ipykernel_14596\\398815207.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder_attn.load_state_dict(torch.load(os.path.join(folder_path, 'encoder_attention.pth'), map_location=device))\n",
      "C:\\Users\\gilpe\\AppData\\Local\\Temp\\ipykernel_14596\\398815207.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  decoder_attn.load_state_dict(torch.load(os.path.join(folder_path, 'decoder_attention.pth'), map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos\n",
    "batch_size = 32\n",
    "hidden_size = 256\n",
    "input_lang_attn, output_lang_attn, train_dataloader_attn = get_dataloader(batch_size)\n",
    "\n",
    "# Cargar los modelos con atención previamente guardados\n",
    "encoder_attn = EncoderRNN(input_lang_attn.n_words, hidden_size).to(device)\n",
    "decoder_attn = AttnDecoderRNN(hidden_size, output_lang_attn.n_words).to(device)\n",
    "\n",
    "encoder_attn.load_state_dict(torch.load(os.path.join(folder_path, 'encoder_attention.pth'), map_location=device))\n",
    "decoder_attn.load_state_dict(torch.load(os.path.join(folder_path, 'decoder_attention.pth'), map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> we re right here\n",
      "= nous sommes juste la\n",
      "< nous sommes presque la presque aussi longtemps <EOS>\n",
      "\n",
      "> she is french\n",
      "= elle est francaise\n",
      "< elle est francaise <EOS>\n",
      "\n",
      "> i m going to hang up now\n",
      "= je vais maintenant raccrocher\n",
      "< je vais maintenant raccrocher <EOS>\n",
      "\n",
      "> she s a determined woman\n",
      "= c est une femme determinee\n",
      "< c est une femme d une grande beaute <EOS>\n",
      "\n",
      "> you re not good at this\n",
      "= vous n y etes pas bons\n",
      "< vous n y etes pas bons <EOS>\n",
      "\n",
      "> i m not writing about you\n",
      "= je n ecris pas a votre sujet\n",
      "< je n ecris pas a ton sujet <EOS>\n",
      "\n",
      "> we re conscientious\n",
      "= nous sommes consciencieux\n",
      "< nous sommes consciencieux <EOS>\n",
      "\n",
      "> he is cranky\n",
      "= il est excentrique\n",
      "< il est excentrique de comprendre <EOS>\n",
      "\n",
      "> i m not asleep\n",
      "= je ne suis pas endormi\n",
      "< je ne suis pas endormi pour faire cela <EOS>\n",
      "\n",
      "> you re finicky\n",
      "= tu es tatillonne\n",
      "< vous etes libres de vous en aller en aller <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_no_attn.eval()\n",
    "decoder_no_attn.eval()\n",
    "\n",
    "# Evaluación del modelo sin atención\n",
    "evaluateRandomly(encoder_no_attn, decoder_no_attn, input_lang_no_attn, output_lang_no_attn, pairs_eng_fra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> he is a rude person\n",
      "= il est malpoli\n",
      "< il est malpoli <EOS>\n",
      "\n",
      "> i m not good with names\n",
      "= j ai du mal avec les noms\n",
      "< j ai du mal avec les noms <EOS>\n",
      "\n",
      "> i m your neighbor\n",
      "= je suis votre voisin\n",
      "< je suis votre voisin <EOS>\n",
      "\n",
      "> i m the same height as he is\n",
      "= je suis de la meme taille que lui\n",
      "< je suis de la meme taille que lui <EOS>\n",
      "\n",
      "> he is what we call a scholar\n",
      "= il est ce qu on appelle un lettre\n",
      "< il est ce qu on appelle un lettre <EOS>\n",
      "\n",
      "> we re fasting\n",
      "= nous faisons la diete\n",
      "< nous faisons la diete <EOS>\n",
      "\n",
      "> i m dying to see you\n",
      "= je desespere de te voir !\n",
      "< je desespere de te voir ! <EOS>\n",
      "\n",
      "> they are exhausted\n",
      "= elles sont crevees\n",
      "< elles sont crevees <EOS>\n",
      "\n",
      "> i m not done with you yet\n",
      "= je n en ai pas encore fini avec toi\n",
      "< je n en ai pas encore fini avec toi <EOS>\n",
      "\n",
      "> he is old enough to understand it\n",
      "= il est assez age pour le comprendre\n",
      "< il est assez age pour le comprendre <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_attn.eval()\n",
    "decoder_attn.eval()\n",
    "\n",
    "# Evaluación del modelo con atención\n",
    "evaluateRandomly(encoder_attn, decoder_attn, input_lang_attn, output_lang_attn, pairs_eng_fra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testeo de modelos con métricas\n",
    "\n",
    "Para cada métrica se van a evaluar aleatoriamente 100 frases obtenidas de los archivos de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métrica 1: BLEU Score\n",
    "\n",
    "El BLEU Score es una métrica que evalúa la calidad de las traducciones comparando n-gramas de la traducción generada con la traducción de referencia, midiendo la precisión y penalizando traducciones demasiado largas o cortas mediante un factor de brevedad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def evaluateRandomly_BLEU(encoder, decoder, input_lang, output_lang, pairs, n=10):\n",
    "    total_bleu = 0  # Acumulador para el BLEU promedio\n",
    "\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        # print('>', pair[0])  # Frase original\n",
    "        # print('=', pair[1])  # Traducción de referencia\n",
    "\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words).replace('<EOS>', '').strip()  # Elimina el token EOS\n",
    "\n",
    "        # print('<', output_sentence)  # Traducción generada\n",
    "\n",
    "        # Calcular BLEU\n",
    "        bleu_score = sentence_bleu([pair[1].split()], output_sentence.split())\n",
    "        total_bleu += bleu_score\n",
    "\n",
    "        # print(f'BLEU score: {bleu_score:.4f}')  # Mostrar BLEU por oración\n",
    "        # print('')\n",
    "\n",
    "    # BLEU promedio para las oraciones evaluadas\n",
    "    average_bleu = total_bleu / n\n",
    "    print(f'Average BLEU score over {n} sentences: {average_bleu:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación del modelo con atención\n",
      "Average BLEU score over 100 sentences: 0.5616\n",
      "Evaluación del modelo sin atención\n",
      "Average BLEU score over 100 sentences: 0.3563\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "\n",
    "# Evaluación del modelo con atención\n",
    "print('Evaluación del modelo con atención')\n",
    "evaluateRandomly_BLEU(encoder_attn, decoder_attn, input_lang_attn, output_lang_attn, pairs_eng_fra, n)\n",
    "\n",
    "# Evaluación del modelo sin atención\n",
    "print('Evaluación del modelo sin atención')\n",
    "evaluateRandomly_BLEU(encoder_no_attn, decoder_no_attn, input_lang_no_attn, output_lang_no_attn, pairs_eng_fra, n)\n",
    "## Métrica 2: METEOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métrica 2: METEOR\n",
    "\n",
    "La métrica METEOR evalúa la calidad de las traducciones comparando palabras y frases de la salida generada con la frase de referencia, considerando coincidencias exactas, sinónimos, raíces y el orden de las palabras, y priorizando el equilibrio entre precisión y recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "def calculate_meteor(reference, hypothesis):\n",
    "\n",
    "    # Convertimos las cadenas de texto en listas de palabras\n",
    "    reference = [reference.split()]\n",
    "    hypothesis = hypothesis.split()\n",
    "    \n",
    "    # Calculamos la métrica METEOR\n",
    "    score = meteor_score(reference, hypothesis)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nltk\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Obtenemos la métrica del modelo con atención\n",
    "def evaluateRandomly_METEOR(encoder, decoder, input_lang, output_lang, pairs, n=10):\n",
    "    total_meteor = 0  # Acumulador para el METEOR promedio\n",
    "\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        # print('>', pair[0])  # Frase original\n",
    "        # print('=', pair[1])  # Traducción de referencia\n",
    "\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words).replace('<EOS>', '').strip()  # Elimina el token EOS\n",
    "\n",
    "        # print('<', output_sentence)  # Traducción generada\n",
    "\n",
    "        # Calcular METEOR\n",
    "        meteor_score = calculate_meteor(pair[1], output_sentence)\n",
    "        total_meteor += meteor_score\n",
    "\n",
    "        # print(f'METEOR score: {meteor_score:.4f}')  # Mostrar METEOR por oración\n",
    "        # print('')\n",
    "\n",
    "    # METEOR promedio para las oraciones evaluadas\n",
    "    average_meteor = total_meteor / n\n",
    "    print(f'Average METEOR score over {n} sentences: {average_meteor:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación del modelo con atención\n",
      "Average METEOR score over 100 sentences: 0.8396\n",
      "Evaluación del modelo sin atención\n",
      "Average METEOR score over 100 sentences: 0.6485\n"
     ]
    }
   ],
   "source": [
    "n=100\n",
    "\n",
    "# Evaluación del modelo con atención\n",
    "print('Evaluación del modelo con atención')\n",
    "evaluateRandomly_METEOR(encoder_attn, decoder_attn, input_lang_attn, output_lang_attn, pairs_eng_fra, n)\n",
    "\n",
    "# Evaluación del modelo sin atención\n",
    "print('Evaluación del modelo sin atención')\n",
    "evaluateRandomly_METEOR(encoder_no_attn, decoder_no_attn, input_lang_no_attn, output_lang_no_attn, pairs_eng_fra, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métrica 3: ROUGE\n",
    "\n",
    "Las métricas ROUGE son un conjunto de métricas que se pueden utilizar para evaluar modelos de traducción en procesamiento del lenguaje natural. Dichas métricas comparan una traducción generada automáticamente con una traducción de referencia producida por humanos. Las métricas ROUGE oscilan entre 0 y 1, y las puntuaciones más altas indican una mayor similitud entre la traducción generada por el modelo y la referencia. Algunos ejemplos de estas métricas son:\n",
    "\n",
    "- ROUGE-1: superposición de unigramas entre la traducción generada por el modelo y la traducción de referencia.\n",
    "- ROUGE-2: superposición de bigramas entre la traducción generada por el modelo y la traducción de referencia.\n",
    "- ROUGE-L: estadísticas basadas en la subsecuencia común más larga, que identifica los n-gramas más largos que ocurren simultáneamente en las secuencias.\n",
    "\n",
    "Usando la librería `rouge_score` podemos calcular estas métricas ROUGE para evaluar nuestros modelos.\n",
    "\n",
    "Para calcular los promedios de las métricas de ROUGE, modificamos la función `evaluateRandomly` para que en cada ejemplo seleccionado aleatoriamente calcule las métricas ROUGE, y al final calcule el promedio de todos los ejemplos. Nos fijaremos principalmente en la métrica F1, ya que esta muestra un equilibrio entre la precisión y el recall, dado que combina ambas. Esto es importante, ya que:\n",
    "\n",
    "- Precisión: mide la proporción de palabras en la traducción generada que están en la traducción de referencia.\n",
    "- Recall: mide la proporción de palabras de la traducción de referencia que están en la traducción generada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métrica 3: ROUGE Score\n",
    "# %pip install rouge-score\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def calculate_rouge(reference, hypothesis):\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, hypothesis)\n",
    "    return scores['rougeL'].fmeasure\n",
    "\n",
    "def evaluateRandomly_ROUGE(encoder, decoder, input_lang, output_lang, pairs, n=10):\n",
    "    total_rouge = 0  # Acumulador para el ROUGE promedio\n",
    "\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        # print('>', pair[0])  # Frase original\n",
    "        # print('=', pair[1])  # Traducción de referencia\n",
    "\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words).replace('<EOS>', '').strip()  # Elimina el token EOS\n",
    "\n",
    "        # print('<', output_sentence)  # Traducción generada\n",
    "\n",
    "        # Calcular ROUGE\n",
    "        rouge_score = calculate_rouge(pair[1], output_sentence)\n",
    "        total_rouge += rouge_score\n",
    "\n",
    "        # print(f'ROUGE score: {rouge_score:.4f}')  # Mostrar ROUGE por oración\n",
    "        # print('')\n",
    "\n",
    "    # ROUGE promedio para las oraciones evaluadas\n",
    "    average_rouge = total_rouge / n\n",
    "    print(f'Average ROUGE score over {n} sentences: {average_rouge:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación del modelo con atención\n",
      "Average ROUGE score over 100 sentences: 0.8574\n",
      "Evaluación del modelo sin atención\n",
      "Average ROUGE score over 100 sentences: 0.6459\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "\n",
    "# Evaluación del modelo con atención\n",
    "print('Evaluación del modelo con atención')\n",
    "evaluateRandomly_ROUGE(encoder_attn, decoder_attn, input_lang_attn, output_lang_attn, pairs_eng_fra, n)\n",
    "\n",
    "# Evaluación del modelo sin atención\n",
    "print('Evaluación del modelo sin atención')\n",
    "evaluateRandomly_ROUGE(encoder_no_attn, decoder_no_attn, input_lang_no_attn, output_lang_no_attn, pairs_eng_fra, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métrica 4: BERT Score\n",
    "\n",
    "El BERT score es una métrica usada para evaluar la calidad de un texto generado por un modelo de lenguaje, que se basa en la similitud semántica entre el texto generado y el de referencia, utilizando los embeddings generados por el modelo de BERT. Este modelo proporciona embeddings contextuales a las palabras de una frase, de forma que genera embeddings diferentes para una misma palabra dependiendo de las palabras a su alrededor y del contexto general de la frase. Esto permite al BERT score capturar de manera más efectiva el significado de las palabras dentro de un contexto, incluso si las palabras exactas en el texto generado y el de referencia no coinciden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "def calculate_bertscore(output_sentence, reference_sentence):\n",
    "    P, R, F1 = score([output_sentence], [reference_sentence], lang=\"en\")\n",
    "    return {\"Precision\": P.item(), \"Recall\": R.item(), \"F1\": F1.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly_BERT(encoder, decoder, input_article, output_abstract, pairs, n=10):\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])  # Texto original\n",
    "        print('=', pair[1])  # Traducción real\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_article, output_abstract)\n",
    "        output_sentence = ' '.join(output_words)  # Traducción generada\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "\n",
    "        # Calcular BERT Score\n",
    "        bert_scores = calculate_bertscore(output_sentence, pair[1])\n",
    "        precision = bert_scores['Precision']\n",
    "        recall = bert_scores['Recall']\n",
    "        f1 = bert_scores['F1']\n",
    "\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1 += f1\n",
    "\n",
    "        print(f'BERTScore Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
    "        print('')\n",
    "    \n",
    "    # Calcular promedios\n",
    "    avg_precision = total_precision / n\n",
    "    avg_recall = total_recall / n\n",
    "    avg_f1 = total_f1 / n\n",
    "\n",
    "    print(f'Average BERTScore Precision over {n} sentences: {avg_precision:.4f}')\n",
    "    print(f'Average BERTScore Recall over {n} sentences: {avg_recall:.4f}')\n",
    "    print(f'Average BERTScore F1 over {n} sentences: {avg_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> you re out of time\n",
      "= votre temps est ecoule\n",
      "< ca fait longtemps qu il est affaire <EOS>\n",
      "\n",
      "BERTScore Precision: 0.8137, Recall: 0.8193, F1: 0.8165\n",
      "\n",
      "> she is in low spirits today\n",
      "= elle n a pas le moral aujourd hui\n",
      "< elle est en ce meme pauvre <EOS>\n",
      "\n",
      "BERTScore Precision: 0.8285, Recall: 0.8087, F1: 0.8185\n",
      "\n",
      "> i am near the station\n",
      "= je me trouve pres de la gare\n",
      "< je me trouve pres de la gare de cette affaire\n",
      "\n",
      "BERTScore Precision: 0.9377, Recall: 0.9675, F1: 0.9524\n",
      "\n",
      "> you re very emotional\n",
      "= vous etes tres emotives\n",
      "< vous etes tres devoir de vouloir y aller <EOS>\n",
      "\n",
      "BERTScore Precision: 0.8264, Recall: 0.9249, F1: 0.8729\n",
      "\n",
      "> i am starting this evening\n",
      "= je commence des ce soir\n",
      "< je commence a comprendre pourquoi tom aime boston <EOS>\n",
      "\n",
      "BERTScore Precision: 0.8033, Recall: 0.8647, F1: 0.8329\n",
      "\n",
      "> i m happy with that\n",
      "= j en suis contente\n",
      "< je suis heureux d etre rentre <EOS>\n",
      "\n",
      "BERTScore Precision: 0.7778, Recall: 0.8085, F1: 0.7929\n",
      "\n",
      "> we re unprejudiced\n",
      "= nous sommes depourvues de prejuges\n",
      "< nous sommes depourvues de prejuges <EOS>\n",
      "\n",
      "BERTScore Precision: 0.9425, Recall: 0.9941, F1: 0.9676\n",
      "\n",
      "> you re really absent minded\n",
      "= vous etes vraiment tete en l air\n",
      "< tu es vraiment tete de l avoir pour le comprendre\n",
      "\n",
      "BERTScore Precision: 0.8641, Recall: 0.8822, F1: 0.8730\n",
      "\n",
      "> i m not selling anything\n",
      "= je ne vends rien du tout\n",
      "< je ne vends rien de rester a l ordinateur <EOS>\n",
      "\n",
      "BERTScore Precision: 0.8427, Recall: 0.9233, F1: 0.8812\n",
      "\n",
      "> i m okay\n",
      "= je me porte bien\n",
      "< je vais bien <EOS>\n",
      "\n",
      "BERTScore Precision: 0.8284, Recall: 0.8617, F1: 0.8447\n",
      "\n",
      "Average BERTScore Precision over 10 sentences: 0.8465\n",
      "Average BERTScore Recall over 10 sentences: 0.8855\n",
      "Average BERTScore F1 over 10 sentences: 0.8653\n"
     ]
    }
   ],
   "source": [
    "encoder_no_attn.eval()\n",
    "decoder_no_attn.eval()\n",
    "\n",
    "# Evaluación del modelo sin atención\n",
    "evaluateRandomly_BERT(encoder_no_attn, decoder_no_attn, input_lang_no_attn, output_lang_no_attn, pairs_eng_fra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> i am very happy in georgia\n",
      "= je suis tres heureux en georgie\n",
      "< je suis tres heureux en georgie <EOS>\n",
      "\n",
      "BERTScore Precision: 0.9320, Recall: 0.9923, F1: 0.9612\n",
      "\n",
      "> we re all dying\n",
      "= nous sommes tous en train de mourir\n",
      "< nous sommes tous en train de mourir <EOS>\n",
      "\n",
      "BERTScore Precision: 0.9400, Recall: 0.9940, F1: 0.9663\n",
      "\n",
      "> i m sick and tired of reading\n",
      "= je suis fatigue de lire\n",
      "< je suis fatigue de lire <EOS>\n",
      "\n",
      "BERTScore Precision: 0.9025, Recall: 0.9870, F1: 0.9429\n",
      "\n",
      "> you are early\n",
      "= vous etes en avance\n",
      "< tu es matinal <EOS>\n",
      "\n",
      "BERTScore Precision: 0.8097, Recall: 0.7966, F1: 0.8031\n",
      "\n",
      "> he s smart\n",
      "= il est intelligent\n",
      "< il est intelligent <EOS>\n",
      "\n",
      "BERTScore Precision: 0.8416, Recall: 0.9469, F1: 0.8912\n",
      "\n",
      "> you are not supposed to smoke here\n",
      "= tu n es pas cense fumer ici\n",
      "< vous n etes pas censee fumer ici <EOS>\n",
      "\n",
      "BERTScore Precision: 0.8214, Recall: 0.8740, F1: 0.8469\n",
      "\n",
      "> she is the one who feeds our dog\n",
      "= c est elle qui nourrit notre chien\n",
      "< c est elle qui nourrit notre chien <EOS>\n",
      "\n",
      "BERTScore Precision: 0.9327, Recall: 0.9962, F1: 0.9634\n",
      "\n",
      "> i am acquainted with the custom\n",
      "= j ai connaissance de cette coutume\n",
      "< j ai connaissance de cette coutume <EOS>\n",
      "\n",
      "BERTScore Precision: 0.9261, Recall: 0.9938, F1: 0.9588\n",
      "\n",
      "> he s a smart little feller\n",
      "= c est un petit gars intelligent\n",
      "< c est un petit gars intelligent <EOS>\n",
      "\n",
      "BERTScore Precision: 0.9150, Recall: 0.9925, F1: 0.9522\n",
      "\n",
      "> i m playing with my friends\n",
      "= je suis en train de jouer avec mes amis\n",
      "< je suis en train de jouer avec mes amies <EOS>\n",
      "\n",
      "BERTScore Precision: 0.9351, Recall: 0.9883, F1: 0.9610\n",
      "\n",
      "Average BERTScore Precision over 10 sentences: 0.8956\n",
      "Average BERTScore Recall over 10 sentences: 0.9562\n",
      "Average BERTScore F1 over 10 sentences: 0.9247\n"
     ]
    }
   ],
   "source": [
    "encoder_attn.eval()\n",
    "decoder_attn.eval()\n",
    "\n",
    "# Evaluación del modelo con atención\n",
    "evaluateRandomly_BERT(encoder_attn, decoder_attn, input_lang_attn, output_lang_attn, pairs_eng_fra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "Con todas las métricas, hemos observado como el modelo con atención obtiene resultados considerablemente mejores que el modelo sin atención. Esto sugiere que el mecanismo de atención mejora las capacidades del modelo para capturar las relaciones contextuales entre palabras y frases. Al asignar diferentes pesos a las partes relevantes de la frase durante la generación de la traducción, se logra una representación mucho más precisa y se logra captar mejor el contexto y el significado de la frase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
